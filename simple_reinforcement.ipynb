{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output # for the hacky render piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = np.array([\n",
    "\n",
    "    ['S', 'O', 'O'],\n",
    "    ['O', 'O', 'D'],\n",
    "    ['O', 'O', 'O'],\n",
    "    ['O', 'O', 'O'],\n",
    "    ['D', 'O', 'O'],\n",
    "    ['O', 'O', 'O'],\n",
    "    ['O', 'O', 'D'],\n",
    "    ['O', 'O', 'G']\n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "actions = {\n",
    "           \"up\":1,\n",
    "           \"right\":2,\n",
    "           \"down\":3,\n",
    "           \"left\":4\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor(action,\n",
    "          state,\n",
    "          env = test_env):\n",
    "\n",
    "    if action == 1:\n",
    "        \n",
    "        update = state[0]-1\n",
    "        \n",
    "        if update < 0:\n",
    "            pass\n",
    "        else:\n",
    "            state[0] = update\n",
    "\n",
    "    elif action == 2: \n",
    "        \n",
    "        update = state[1]+1\n",
    "        \n",
    "        if update > 2:\n",
    "            pass\n",
    "        else:\n",
    "            state[1] = update\n",
    "\n",
    "    elif action == 3:\n",
    "        \n",
    "        update = state[0]+1\n",
    "       \n",
    "        if update < 0:\n",
    "            pass\n",
    "        else:\n",
    "            state[0] = update\n",
    "\n",
    "    else:\n",
    "        \n",
    "        update = state[1]-1\n",
    "\n",
    "        if update < 0:\n",
    "            pass\n",
    "        else:\n",
    "            state[1] = update\n",
    "            \n",
    "    # return vals        \n",
    "\n",
    "    i0 = state[0]\n",
    "    i1 = state[1]\n",
    "\n",
    "    updated_state = env[i0][i1]\n",
    "    \n",
    "    if updated_state == \"G\":\n",
    "        \n",
    "        DONE = True\n",
    "        reward = 1\n",
    "    \n",
    "    elif updated_state == \"D\":\n",
    "        \n",
    "        DONE = True\n",
    "        reward = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        DONE = False\n",
    "        reward = 0\n",
    "        \n",
    "    return state,DONE,reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayer(state,\n",
    "              n_episode,\n",
    "              env=test_env):\n",
    "    \n",
    "    copy_env = env.copy()\n",
    "    \n",
    "    copy_env[state[0]][state[1]] = \"*\" \n",
    "\n",
    "    env_string = '\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in copy_env])\n",
    "\n",
    "    sys.stdout.write(\"Episode \"+str(n_episode)+'\\n\\r'+env_string)\n",
    "    time.sleep(.05)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define execution vars\n",
    "\n",
    "start_state = [0,0]\n",
    "all_rewards = {} # key (n_episode) : value (array of vals to take the max of)\n",
    "\n",
    "n_episodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the Q-learning/table vars\n",
    "\n",
    "# in essence: for each state we need to get the value of each action (four values per 12*3 states)\n",
    "# as runs start to become more successful, then values start to become more of a signal\n",
    "\n",
    "#Initialize table with all zeros\n",
    "\n",
    "QTABLE = np.array([\n",
    "    \n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]],\n",
    "    [[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "\n",
    "])\n",
    "\n",
    "lr = .8\n",
    "y = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30\n",
      "\r",
      "*   O   O   \n",
      "O   O   D   \n",
      "O   O   O   \n",
      "O   O   O   \n",
      "D   O   O   \n",
      "O   O   O   \n",
      "O   O   D   \n",
      "O   O   G   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-7d9c25a3cfce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# display grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mdisplayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_episode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mQTABLE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQTABLE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m                         \u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m                         \u001b[0mQTABLE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-171-d172c2e7497a>\u001b[0m in \u001b[0;36mdisplayer\u001b[1;34m(state, n_episode, env)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Episode \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_episode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n\\r'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0menv_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(1,n_episodes):\n",
    "    \n",
    "    n_step = 0\n",
    "    running_states = [start_state]\n",
    "    \n",
    "    while n_step <99:\n",
    "\n",
    "        step_rewards = []\n",
    "\n",
    "        a = np.argmax(QTABLE[running_states[n_step]] + np.random.randn(1,len(actions))*(1./(e+1)))\n",
    "\n",
    "        s,DONE,reward = actor(\n",
    "\n",
    "            action = a,\n",
    "            state = list(running_states[n_step])\n",
    "\n",
    "        )\n",
    "\n",
    "        # display grid\n",
    "        displayer(state=s,n_episode=e)\n",
    "        \n",
    "        QTABLE[s,a-1] = QTABLE[s,a-1] + \\\n",
    "                        lr*(reward + y*np.max(Q[s]) - \\\n",
    "                        QTABLE[s,a-1])\n",
    "\n",
    "        running_states.append(s)\n",
    "\n",
    "        step_rewards.append(reward) # get max of this\n",
    "\n",
    "        all_rewards[e] = max(step_rewards)\n",
    "\n",
    "        n_step += 1\n",
    "\n",
    "        if DONE:\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
